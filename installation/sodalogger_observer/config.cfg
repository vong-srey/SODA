# all "keys" must be written in "CamelCase", where the first char is "Uppercase"
# all "values" must be written in "CamelCase", where the first char is "lowercase"

# Possible values: SigarSupport, Minix
# SigarSupport includes: Linux, Windows, HPUX, Solaris, AIX, FreeBSD, MacOSX
# if the OS that this tool is going to run on is in this list {Linux, Windows, HPUX, Solaris, AIX, FreeBSD, MacOSX}, please use "SigarSupport" instead of the real name (e.g. Windows).
# Minix and other OS(es) that are non-supported by Sigar, you have to implements the collector tool
OS=SigarSupport



# log frequency in milliseconds
LogFrequency=1000



# "yes" if you want to activate the AppLogger to log the application (itself) performance, error and status
# "no" otherwise
# if "no" is chosen, the other properties for AppLogger will be ignored.
# The Logger is the wrapper of log4j
AppLogger=yes
# where the logs should be stored. Please specify only the directory that the logs will be stored
# i.e. Logs/AppLogs is the folder to store the logs. the log file will be Logs/AppLogs/app.log-$DATE
AppLoggerLogFolder=Logs/AppLogs
# only "true" or "false"
AppLoggerLogImmediateFlush=true
# only "true" or "false"
AppLoggerLogAppend=true
# only non-decimal number (int). number of log files can be stored in the storage folder before the earliest log get deleted.
AppLoggerLogMaxNumberOfDays=1
# only "true" or "false". "true", the earliest log will be compressed before the origianl is deleted (when the number of logs in the storage folder is greater or equals  to the maxNumberOfDays ). "false" it won't be compressed, but it will be delted.
AppLoggerLogCompressBackups=false
# set the level of the logger
AppLoggerLogThreshold=ALL
# this pattern is log4j pattern.
AppLoggerLogPattern=%d{dd/MMM/yyyy-HH:mm:ss.SSS} %-5p %c{1}:%L - %m%n



# "yes" if you want to activate the CPUCollector to collect and log the CPU performance
# "no" otherwise
# if "no" is chosen, the other properties for CPUCollector will be ignored.
# The Logger is the wrapper of log4j
CPUCollector=yes
# where the logs should be stored. Please specify only the directory that the logs will be stored
# i.e. Logs/CPULogs is the folder to store the logs. the log file will be Logs/CPULogs/CPU-$DATE
CPUCollectorLogFolder=Logs/CPULogs
# only "true" or "false"
CPUCollectorLogImmediateFlush=true
# only "true" or "false"
CPUCollectorLogAppend=true
# only non-decimal number (int). number of log files can be stored in the storage folder before the earliest log get deleted.
CPUCollectorLogMaxNumberOfDays=1
# only "true" or "false". "true", the earliest log will be compressed before the origianl is deleted (when the number of logs in the storage folder is greater or equals  to the maxNumberOfDays ). "false" it won't be compressed, but it will be delted.
CPUCollectorLogCompressBackups=false
# this pattern is log4j pattern. It is recommanded to use this patter "%d{dd MMM yyyy HH:mm:ss,SSS} %m%n".
CPUCollectorLogPattern=%d{dd/MMM/yyyy-HH:mm:ss.SSS} %m%n



# "yes" if you want to activate the DFCollector to collect and log the DF performance (DF data is the same as running df command in unix/linux)
# "no" otherwise
# if "no" is chosen, the other properties for DFCollector will be ignored.
# The Logger is the wrapper of log4j
DFCollector=yes
# where the logs should be stored. Please specify only the directory that the logs will be stored
# i.e. Logs/DFLogs is the folder to store the logs. the log file will be Logs/DFLogs/DF-$DATE
DFCollectorLogFolder=Logs/DFLogs
# only "true" or "false"
DFCollectorLogImmediateFlush=true
# only "true" or "false"
DFCollectorLogAppend=true
# only non-decimal number (int). number of log files can be stored in the storage folder before the earliest log get deleted.
DFCollectorLogMaxNumberOfDays=1
# only "true" or "false". "true", the earliest log will be compressed before the origianl is deleted (when the number of logs in the storage folder is greater or equals  to the maxNumberOfDays ). "false" it won't be compressed, but it will be delted.
DFCollectorLogCompressBackups=false
# this pattern is log4j pattern. It is recommanded to use this patter "%d{dd MMM yyyy HH:mm:ss,SSS} %m%n".
DFCollectorLogPattern=%d{dd/MMM/yyyy-HH:mm:ss.SSS} %m%n



# "yes" if you want to activate the DiskCollector to collect and log the Disk performance (this is the data of amount of writting and reading = disk io)
# "no" otherwise
# if "no" is chosen, the other properties for DiskCollector will be ignored.
# The Logger is the wrapper of log4j
DiskCollector=yes
# where the logs should be stored.  Please specify only the directory that the logs will be stored
# i.e. Logs/DiskLogs is the folder to store the logs. the log file will be Logs/DiskLogs/Disk-$DATE
DiskCollectorLogFolder=Logs/DiskLogs
# only "true" or "false"
DiskCollectorLogImmediateFlush=true
# only "true" or "false"
DiskCollectorLogAppend=true
# only non-decimal number (int). number of log files can be stored in the storage folder before the earliest log get deleted.
DiskCollectorLogMaxNumberOfDays=1
# only "true" or "false". "true", the earliest log will be compressed before the origianl is deleted (when the number of logs in the storage folder is greater or equals  to the maxNumberOfDays ). "false" it won't be compressed, but it will be delted.
DiskCollectorLogCompressBackups=false
# this pattern is log4j pattern. It is recommanded to use this patter "%d{dd MMM yyyy HH:mm:ss,SSS} %m%n".
DiskCollectorLogPattern=%d{dd/MMM/yyyy-HH:mm:ss.SSS} %m%n



# "yes" if you want to activate the MemoryCollector to collect and log the Memory performance (amount of Total, Used and Free of Memory and Swap)
# "no" otherwise
# if "no" is chosen, the other properties for MemoryCollector will be ignored.
# The Logger is the wrapper of log4j
MemoryCollector=yes
# where the logs should be stored. Please specify only the directory that the logs will be stored
# i.e. Logs/MemoryLogs is the folder to store the logs. the log file will be Logs/MemoryLogs/Memory-$DATE
MemoryCollectorLogFolder=Logs/MemoryLogs
# only "true" or "false"
MemoryCollectorLogImmediateFlush=true
# only "true" or "false"
MemoryCollectorLogAppend=true
# only non-decimal number (int). number of log files can be stored in the storage folder before the earliest log get deleted.
MemoryCollectorLogMaxNumberOfDays=1
# only "true" or "false". "true", the earliest log will be compressed before the origianl is deleted (when the number of logs in the storage folder is greater or equals  to the maxNumberOfDays ). "false" it won't be compressed, but it will be delted.
MemoryCollectorLogCompressBackups=false
# this pattern is log4j pattern. It is recommanded to use this patter "%d{dd MMM yyyy HH:mm:ss,SSS} %m%n".
MemoryCollectorLogPattern=%d{dd/MMM/yyyy-HH:mm:ss.SSS} %m%n



# "yes" if you want to activate the NetworkCollector to collect and log the Network performance (mainly, TCP traffic packets)
# "no" otherwise
# if "no" is chosen, the other properties for NetworkCollector will be ignored.
# The Logger is the wrapper of log4j
NetworkCollector=yes
# where the logs should be stored. Please specify only the directory that the logs will be stored
# i.e. Logs/NetworkLogs is the folder to store the logs. the log file will be Logs/NetworkLogs/Network-$DATE
NetworkCollectorLogFolder=Logs/NetworkLogs
# only "true" or "false"
NetworkCollectorLogImmediateFlush=true
# only "true" or "false"
NetworkCollectorLogAppend=true
# only non-decimal number (int). number of log files can be stored in the storage folder before the earliest log get deleted.
NetworkCollectorLogMaxNumberOfDays=1
# only "true" or "false". "true", the earliest log will be compressed before the origianl is deleted (when the number of logs in the storage folder is greater or equals  to the maxNumberOfDays ). "false" it won't be compressed, but it will be delted.
NetworkCollectorLogCompressBackups=false
# this pattern is log4j pattern. It is recommanded to use this patter "%d{dd MMM yyyy HH:mm:ss,SSS} %m%n".
NetworkCollectorLogPattern=%d{dd/MMM/yyyy-HH:mm:ss.SSS} %m%n



# "yes" if you want to activate the ProcsCollector to collect and log the processes performances (the processes' owner, CPU usage, memory usage, threads and its status). You need to specify the Processes' PID that you want to collect the performances in the ProcsPIDs
# "no" otherwise
# if "no" is chosen, the other properties for ProcsCollector will be ignored.
# The Logger is the wrapper of log4j
ProcsCollector=yes
# where the logs should be stored. Please specify only the directory that the logs will be stored
# i.e. Logs/ProcsLogs is the folder to store the logs. the log file will be Logs/ProcsLogs/Procs-$DATE
ProcsCollectorLogFolder=Logs/ProcsLogs
# only "true" or "false"
ProcsCollectorLogImmediateFlush=true
# only "true" or "false"
ProcsCollectorLogAppend=true
# only non-decimal number (int). number of log files can be stored in the storage folder before the earliest log get deleted.
ProcsCollectorLogMaxNumberOfDays=1
# only "true" or "false". "true", the earliest log will be compressed before the origianl is deleted (when the number of logs in the storage folder is greater or equals  to the maxNumberOfDays ). "false" it won't be compressed, but it will be delted.
ProcsCollectorLogCompressBackups=false
# this pattern is log4j pattern. It is recommanded to use this patter "%d{dd MMM yyyy HH:mm:ss,SSS} %m%n".
ProcsCollectorLogPattern=%d{dd/MMM/yyyy-HH:mm:ss.SSS} %m%n
# specify all the PID(s) of the processes that you want to collect its performances in this list.
# Each PID is seperated by ",". e.g. pid1,pid2,pid3,...  another example 771,1124,2230
ProcsCollectorPIDsList=1744, 788, 1921






# This block is the properties for Observer
# Tell observer how often it should analyse all the system performances (through log). The number written here is in seconds (it must be an integer - without floating point)
ObserveFrequency=1
# Tell observer how often it should send the problems to the system administrator email. The number written here is in seconds (it must be an integer - without floating point)
ResendEmailFrequency=30
# Url to tell the host and the port of the elasticsearch server. the must always be "/_search" at the end of the url
ElasticsearchSearchUrl=http://172.20.28.126:9200/_search
# The time zone of Elasticsearch server. this must be an integer (without floating point). 00 if it is on UTC
ElasticsearchServerTimeZone=+12
# Email address that used as the sender on the alert email
FromAddress=vong.srey@orionhealth.com
# Mail server that is used to send the alert email
SMTPHost=zimbra
# The subject that will be placed on the alert email 
AlertEmailSubject=This is an alert from your server!
# The body (before putting the actual problem message that generated by Observer) and the signature for the email
AlertBody=Kia Ora! \n\nI'm the SODA robot who is looking after your servers. I've found some issues (based on the criterias you told me) as follow: \n\n
AlertSignature=\n\nCiao,\n\nSODA, CSS Team
Debug=true